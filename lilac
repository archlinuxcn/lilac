#!/usr/bin/python3 -u

from __future__ import annotations

import os
import sys
import traceback
import logging
import configparser
import time
from collections import defaultdict
from typing import Set, Dict, List, Any
import textwrap
from pathlib import Path

import prctl
from toposort import toposort_flatten
import structlog

topdir = Path(__file__).resolve().parent
sys.path.append(str(topdir))
sys.path.append(str(topdir / 'vendor'))

from myutils import at_dir, execution_timeout, lock_file
from serializer import PickledData
from nicelogger import enable_pretty_logging

from lilac2.packages import (
  DependencyManager, get_dependency_map, get_changed_packages,
  Dependency,
)
from lilac2.cmd import (
  run_cmd, git_pull_override, git_push, pkgrel_changed,
  git_reset_hard, get_git_branch,
)
from lilac2.tools import kill_child_processes, redirect_output
from lilac2.repo import Repo
from lilac2.const import mydir, _G
from lilac2.nvchecker import packages_need_update, nvtake, NvResults
from lilac2.typing import LilacMod
from lilac2 import pkgbuild
from lilac2.building import lilac_build, MissingDependencies, SkipBuild
from lilac2 import slogconf

# Note that source dirs need to be created in advance
BIND_MOUNTS = [
  os.path.expanduser('~/.cargo') + ':/build/.cargo',
  os.path.expanduser('~/go') + ':/build/go',
  os.path.expanduser('~/.cache/archbuild-bind-cache') + ':/build/.cache',
  os.path.expanduser('~/.cache/go-build') + ':/build/.cache/go-build',
  os.path.expanduser('~/.cache/pip') + ':/build/.cache/pip',
]

config = configparser.ConfigParser()
config.optionxform = lambda option: option # type: ignore
config.read(topdir / 'config.ini')

# Setting up enviroment variables
os.environ.update(config.items('enviroment variables'))
os.environ['PATH'] = str(topdir) + ':' + os.environ['PATH']

DESTDIR = os.path.expanduser(config.get('repository', 'destdir'))
MYNAME = config.get('lilac', 'name')

building_packages: Set[str] = set()
nvdata: Dict[str, NvResults] = {}
DEPMAP: Dict[str, Set[Dependency]] = {}
DEPENDS: Dict[str, Set[Dependency]] = {}

logger = logging.getLogger(__name__)
build_logger_old = logging.getLogger('build')
build_logger = structlog.get_logger(logger_name='build')
REPO = _G.repo = Repo(config)
logdir: Path

EMPTY_COMMIT = '4b825dc642cb6eb9a060e54bf8d69288fbee4904'

def setup_build_logger() -> None:
  handler = logging.FileHandler(mydir / 'build.log')
  handler.setFormatter(logging.Formatter('[%(asctime)s] %(message)s', '%Y-%m-%d %H:%M:%S'))
  build_logger_old.addHandler(handler)

  logfile = (mydir / 'build-log.json').open('a')

  processors = [
    slogconf.exc_info,
    slogconf.add_timestamp,
    structlog.processors.format_exc_info,
    slogconf.json_renderer,
  ]

  logger_factory = structlog.PrintLoggerFactory(
    file=logfile)

  structlog.configure(
    processors = processors,
    logger_factory = logger_factory,
  )

def build_package(logdir: Path, package: str, mod: LilacMod) -> bool:
  logger.info('building %s', package)
  logfile = logdir / f'{package}.log'
  start_time = time.time()
  try:
    _G.mod = mod
    _G.epoch = _G.pkgver = _G.pkgrel = None
    built_successfully = False
    update_info = nvdata[package]
    maintainer = REPO.find_maintainers(mod)[0]
    time_limit_hours = getattr(mod, 'time_limit_hours', 1)
    os.environ['PACKAGER'] = '%s (on behalf of %s) <%s>' % (
      MYNAME, maintainer.name, maintainer.email)
    try:
      with logfile.open('wb') as f, \
          redirect_output(f.fileno()), \
          execution_timeout(time_limit_hours * 3600):
        lilac_build(
          mod, REPO,
          update_info = update_info,
          depends = DEPENDS.get(package, ()),
          bindmounts = BIND_MOUNTS,
        )
    except TimeoutError:
      kill_child_processes()
      raise
    sign_and_copy()
    built_successfully = True
    assert _G.pkgver is not None
    assert _G.pkgrel is not None
    build_logger_old.info(
      '%s %s [%s] successful after %ds',
      package, update_info.newver,
      pkgbuild.format_package_version(_G.epoch, _G.pkgver, _G.pkgrel),
      time.time() - start_time)
    build_logger.info(
      'successful',
      pkgbase = package,
      nv_version = update_info.newver,
      pkg_version = pkgbuild.format_package_version(_G.epoch, _G.pkgver, _G.pkgrel),
      elapsed = time.time() - start_time)
  except (MissingDependencies, pkgbuild.DowngradingError):
    build_logger_old.error(
      '%s %s failed after %ds',
      package, update_info.newver, time.time() - start_time)
    build_logger.exception(
      'failed',
      pkgbase = package,
      nv_version = update_info.newver,
      elapsed = time.time() - start_time)
    raise
  except SkipBuild as e:
    logger.warning('%s %s skipped because %s',
                   package, update_info.newver, e.msg)
    build_logger_old.warning(
      '%s %s skipped after %ds',
      package, update_info.newver, time.time() - start_time)
    build_logger.warning('skipped',
                         pkgbase = package,
                         nv_version = update_info.newver,
                         msg = e.msg,
                         elapsed = time.time() - start_time)
  except Exception as e:
    tb = traceback.format_exc()
    logger.exception('packaging error')
    REPO.send_error_report(_G.mod, exc=(e, tb), logfile=logfile)
    build_logger_old.error(
      '%s %s [%s] failed after %ds',
      package, update_info.newver,
      pkgbuild.format_package_version(_G.epoch, _G.pkgver, _G.pkgrel),
      time.time() - start_time)
    build_logger.exception(
      'failed',
      pkgbase = package,
      nv_version = update_info.newver,
      pkg_version = pkgbuild.format_package_version(_G.epoch, _G.pkgver, _G.pkgrel),
      elapsed = time.time() - start_time)
  finally:
    del _G.mod, _G.epoch, _G.pkgver, _G.pkgrel

  return built_successfully

def sign_and_copy() -> None:
  if not DESTDIR:
    return
  pkgs = [x for x in os.listdir() if x.endswith(('.pkg.tar.xz', '.pkg.tar.zst'))]
  for pkg in pkgs:
    run_cmd(['gpg', '--pinentry-mode', 'loopback', '--passphrase', '',
             '--detach-sign', '--', pkg])
  for f in os.listdir():
    if not f.endswith(('.pkg.tar.xz', '.pkg.tar.xz.sig', '.pkg.tar.zst', '.pkg.tar.zst.sig')):
      continue
    try:
      os.link(f, os.path.join(DESTDIR, f))
    except FileExistsError:
      pass

def git_last_commit() -> str:
  cmd = ['git', 'log', '-1', '--format=%H']
  return run_cmd(cmd).strip()

def start_build(repo: Repo, failed: Set[str], built: Set[str]) -> None:
  # built is used to collect built package names
  global DEPENDS

  building_depmap = {}
  for p in building_packages:
    building_depmap[p] = DEPMAP[p]

  dep_building_map: Dict[str, Set[str]] = {}
  nonexistent: Dict[str, List[Dependency]] = defaultdict(list)
  for name, ds in building_depmap.items():
    for d in ds:
      if not d.resolve():
        if not repo.manages(d):
          logger.warning('%s depends on %s, but it\'s not managed.',
                         name, d)
          nonexistent[name].append(d)
          continue
        # we need build this too
        building_packages.add(d.pkgname)

    dep_building_map[name] = set()
    for x in ds:
      pkgbase = x.pkgdir.name
      dep_building_map[name].add(pkgbase)
      # a dependency may depend other packages, we need their relations
      if pkgbase in DEPMAP:
        dep_building_map[pkgbase] = {
          x.pkgdir.name for x in DEPMAP[pkgbase]}

  for name, deps in nonexistent.items():
    repo.send_error_report(
      repo.mods[name], subject='软件包 %s 的 lilac.py 或 lilac.yaml 指定了不存在的依赖',
      msg = f'''软件包 {name} 的 lilac.py (lilac.yaml) 指定了 depends (repo_depends)，然而其直接或者间接的依赖项 {deps!r} 并不在本仓库中。
''')

  packages = toposort_flatten(dep_building_map)
  # filter out already built packages
  packages = [x for x in packages if x in building_packages]

  # ensure all packages including dependents are included
  for p in packages:
    building_depmap[p] = DEPMAP[p]

  # used to decide what to install when building
  DEPENDS = building_depmap

  try:
    logger.info('building these packages: %r', packages)
    for pkg in packages:
      if pkg in failed:
        # marked as failed, skip
        continue

      path = repo.repodir / pkg
      with at_dir(path):
        try:
          if build_package(logdir, pkg, repo.mods[pkg]):
            built.add(pkg)
          else:
            failed.add(pkg)

        except pkgbuild.ConflictWithOfficialError as e:
          reason = ''
          if e.groups:
            reason += f'软件包被加入了官方组：{e.groups}\n'
          if e.packages:
            reason += f'软件包将取代官方包：{e.packages}\n'

          repo.send_error_report(
            repo.mods[pkg],
            subject='%s 与官方软件库冲突',
            msg = reason,
          )
          failed.add(pkg)

        except MissingDependencies as e:
          reason = ''

          faileddeps = e.deps & failed
          if faileddeps:
            reason += '唔，这些包没能成功打包呢：%r' % faileddeps

          repo.send_error_report(repo.mods[pkg], subject='%s 出现依赖问题',
                                 msg = '''\
在成功地编译打包 {built} 之后，{pkg} 依旧依赖 {deps}。

{reason}'''.format(
    built = built, deps = e.deps, pkg = pkg, reason = reason,
  ))
          failed.add(pkg)
        except pkgbuild.DowngradingError as e:
          repo.send_error_report(repo.mods[pkg], subject='%s 新打的包比仓库里的包旧', msg=textwrap.dedent(f'''
          包 {e.pkgname} 打的版本为 {e.built_version}，但在仓库里已有较新版本 {e.repo_version}。
          '''))
          failed.add(pkg)

  except KeyboardInterrupt:
    logger.info('keyboard interrupted, bye~')

def main_may_raise(D: Dict[str, Any], pkgs_to_build: List[str]) -> None:
  global DEPMAP

  failed_info = D.get('failed', {})

  if get_git_branch() != 'master':
    raise Exception('repo not on master, aborting.')

  git_reset_hard()
  git_pull_override()
  failed = REPO.load_managed_lilac_and_report()

  depman = DependencyManager(REPO.repodir)
  DEPMAP = get_dependency_map(depman, REPO.mods)

  if pkgs_to_build:
    all_mods = REPO.mods
    REPO.mods = {}
    for pkg_to_build in pkgs_to_build:
      for dep in DEPMAP[pkg_to_build]:
        REPO.mods[dep.pkgname] = all_mods[dep.pkgname]
      REPO.mods[pkg_to_build] = all_mods[pkg_to_build]

  _nvdata, unknown, rebuild = packages_need_update(REPO)
  nvdata.update(_nvdata)

  if pkgs_to_build:
    need_update: Set[str] = set()
    need_rebuild_failed: Set[str] = set()
    need_rebuild_pkgrel: Set[str] = set()
    rebuild = rebuild | set(pkgs_to_build)
  else:
    U = set(REPO.mods)
    last_commit = D.get('last_commit', EMPTY_COMMIT)
    changed = get_changed_packages(last_commit, 'HEAD') & U

    failed_prev = set(failed_info.keys())
    # no update from upstream, but build instructions have changed; rebuild
    # failed ones
    need_rebuild_failed = failed_prev & changed
    # if pkgrel is updated, build a new release
    need_rebuild_pkgrel = {x for x in changed
                          if pkgrel_changed(last_commit, 'HEAD', x)} - unknown

  updated = {x for x, y in nvdata.items()
              if y.oldver != y.newver}
  failed_updated = {k for k, v in failed_info.items()
                    if k in nvdata and nvdata[k].newver != v}
  # build updated; if last build failed but it gets updated once more,
  # build it again
  need_update = updated | failed_updated

  all_building = need_update | need_rebuild_failed | need_rebuild_pkgrel \
      | rebuild

  logger.info('these updated (pkgrel) packages should be rebuilt: %r',
              need_rebuild_pkgrel or None)
  logger.info('these previously-failed packages should be rebuilt: %r',
              need_rebuild_failed or None)
  logger.info('these packages are updated as detected by nvchecker: %r',
              need_update or None)
  logger.info('these packages need rebuilding'
              ' as detected by nvchecker or manually specified: %r',
              rebuild or None)

  building_packages.update(all_building)
  update_succeeded: Set[str] = set()

  try:
    build_logger.info('build start')
    start_build(REPO, failed, update_succeeded)
    D['last_commit'] = git_last_commit()
  finally:
    build_logger.info('build end')
    # handle what has been processed even on exception
    failed_info.update({k: nvdata[k].newver for k in failed if k in nvdata})

    for x in update_succeeded:
      if x in failed_info:
        del failed_info[x]
    D['failed'] = failed_info

    if config.getboolean('lilac', 'rebuild_failed_pkgs'):
      if update_succeeded:
        nvtake(update_succeeded, REPO.mods)
    else:
      if need_update or rebuild:
        # only nvtake packages we have tried to build (excluding unbuilt
        # packages due to internal errors)
        built = update_succeeded | failed
        update_nv = built & (need_update | rebuild)
        nvtake(update_nv, REPO.mods)

    git_reset_hard()
    if config.getboolean('lilac', 'git_push'):
      git_push()

def main(pkgs_to_build: List[str]) -> None:
  store = mydir / 'store'
  with PickledData(store, default={}) as D:
    try:
      main_may_raise(D, pkgs_to_build)
    except Exception:
      tb = traceback.format_exc()
      logger.exception('unexpected error')
      subject = '运行时错误'
      msg = '调用栈如下：\n\n' + tb
      REPO.report_error(subject, msg)

def setup() -> None:
  prctl.set_child_subreaper(1)
  global logdir

  logdir = mydir / 'log' / time.strftime('%Y-%m-%dT%H:%M:%S')
  logdir.mkdir(parents=True, exist_ok=True)
  logfile = logdir / 'lilac-main.log'
  fd = os.open(logfile, os.O_WRONLY | os.O_CREAT, 0o644)
  os.dup2(fd, 1)
  os.dup2(fd, 2)
  os.close(fd)

  enable_pretty_logging('DEBUG')
  if 'MAKEFLAGS' not in os.environ:
    cores = os.cpu_count()
    if cores is not None:
      os.environ['MAKEFLAGS'] = '-j{0}'.format(cores)

  lock_file(mydir / '.lock')

  setup_build_logger()
  os.chdir(REPO.repodir)

  dbpath = mydir / 'pacmandb'
  dbpath.mkdir(exist_ok=True)
  pkgbuild.init_data(dbpath)

if __name__ == '__main__':
  try:
    setup()

    main(sys.argv[1:])
  except Exception:
    logger.exception('unexpected error')
