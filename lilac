#!/usr/bin/python3 -u

from __future__ import annotations

import os
import sys
import traceback
import logging
import time
from collections import defaultdict
from typing import Set, Dict, List, Any, Optional, Tuple
from pathlib import Path
import graphlib
import json

import prctl
import structlog

topdir = Path(__file__).resolve().parent
if (topdir / 'lilac2').exists():
  # In-tree
  sys.path.append(str(topdir))
  sys.path.append(str(topdir / 'lilac2' / 'vendor'))
else:
  # Installed as a system package
  import lilac2
  sys.path.append(str(Path(lilac2.__file__).parent / 'vendor'))

from myutils import at_dir, execution_timeout, lock_file
from serializer import PickledData
from nicelogger import enable_pretty_logging

from lilac2.packages import (
  DependencyManager, get_dependency_map, get_changed_packages,
  Dependency,
)
from lilac2.cmd import (
  run_cmd, git_pull_override, git_push, pkgrel_changed,
  git_reset_hard, get_git_branch,
)
from lilac2.tools import kill_child_processes, redirect_output, read_config
from lilac2.repo import Repo
from lilac2.const import mydir, _G, PACMAN_DB_DIR
from lilac2.nvchecker import packages_need_update, nvtake, NvResults
from lilac2.typing import LilacMod
from lilac2.nomypy import BuildResult, BuildReason # type: ignore
from lilac2 import pkgbuild
from lilac2.building import lilac_build, MissingDependencies, SkipBuild
from lilac2 import slogconf
from lilac2.api import notify_maintainers
try:
  from lilac2 import db
except ImportError:
  class db: # type: ignore
    USE = False

config = read_config()

# Setting up enviroment variables
os.environ.update(config.get('envvars', ()))
os.environ['PATH'] = str(topdir) + ':' + os.environ['PATH']

DESTDIR = os.path.expanduser(config['repository'].get('destdir', ''))
MYNAME = config['lilac']['name']

def get_bindmounts(
  bindmounts: Optional[Dict[str, str]],
) -> List[str]:
  if bindmounts is None:
    return []

  items = [(os.path.expanduser(src), dst)
           for src, dst in bindmounts.items()]
  items.sort(reverse=True)
  return [f'{src}:{dst}' for src, dst in items]

BIND_MOUNTS = get_bindmounts(config.get('bindmounts'))

# dict for perserving insertion order
building_packages: Dict[str, Tuple[()]] = {}
nvdata: Dict[str, NvResults] = {}
DEPMAP: Dict[str, Set[Dependency]] = {}
DEPENDS: Dict[str, Set[Dependency]] = {}
build_reasons: Dict[str, List[BuildReason]] = defaultdict(list)

logger = logging.getLogger(__name__)
build_logger_old = logging.getLogger('build')
build_logger = structlog.get_logger(logger_name='build')
REPO = _G.repo = Repo(config)
logdir: Path

EMPTY_COMMIT = '4b825dc642cb6eb9a060e54bf8d69288fbee4904'

def setup_build_logger() -> None:
  handler = logging.FileHandler(mydir / 'build.log')
  handler.setFormatter(logging.Formatter('[%(asctime)s] %(message)s', '%Y-%m-%d %H:%M:%S'))
  build_logger_old.addHandler(handler)

  logfile = (mydir / 'build-log.json').open('a')

  processors = [
    slogconf.exc_info,
    slogconf.add_timestamp,
    structlog.processors.format_exc_info,
    slogconf.json_renderer,
  ]

  logger_factory = structlog.PrintLoggerFactory(
    file=logfile)

  structlog.configure(
    processors = processors,
    logger_factory = logger_factory,
  )

def build_package(
  package: str, mod: LilacMod,
) -> tuple[BuildResult, Optional[str]]:
  '''return BuildResult and version string if successful'''
  pkg_version = None
  rusage = None
  try:
    _G.mod = mod
    _G.epoch = _G.pkgver = _G.pkgrel = None
    update_info = nvdata[package]
    maintainer = REPO.find_maintainers(mod)[0]
    time_limit_hours = getattr(mod, 'time_limit_hours', 1)
    os.environ['PACKAGER'] = '%s (on behalf of %s) <%s>' % (
      MYNAME, maintainer.name, maintainer.email)
    try:
      # we have set a time limit in run_build_cmd, but guard against possible
      # other issues here. Add 120s for other work
      with execution_timeout(time_limit_hours * 3600 + 120):
        rusage, exc = lilac_build(
          mod, REPO,
          update_info = update_info,
          depends = DEPENDS.get(package, ()),
          bindmounts = BIND_MOUNTS,
        )
    except TimeoutError:
      kill_child_processes()
      raise
    if exc:
      raise exc

    staging = getattr(mod, 'staging', False)
    if staging:
      destdir = os.path.join(DESTDIR, 'staging')
      if not os.path.isdir(destdir):
        os.mkdir(destdir)
    else:
      destdir = DESTDIR
    sign_and_copy(destdir)
    if staging:
      notify_maintainers('软件包已被置于 staging 目录，请查验后手动发布。')
      result = BuildResult.staged()
    else:
      result = BuildResult.successful()

    # mypy thinks they are None...
    assert _G.pkgver is not None
    assert _G.pkgrel is not None
    pkg_version = pkgbuild.format_package_version(_G.epoch, _G.pkgver, _G.pkgrel)

  except SkipBuild as e:
    result = BuildResult.skipped(e.msg)
  except Exception as e:
    result = BuildResult.failed(e)
  finally:
    del _G.mod, _G.epoch, _G.pkgver, _G.pkgrel

  result.rusage = rusage
  return result, pkg_version

def sign_and_copy(dest: str) -> None:
  pkgs = [x for x in os.listdir() if x.endswith(('.pkg.tar.xz', '.pkg.tar.zst'))]
  for pkg in pkgs:
    run_cmd(['gpg', '--pinentry-mode', 'loopback', '--passphrase', '',
             '--detach-sign', '--', pkg])
  for f in os.listdir():
    if not f.endswith(('.pkg.tar.xz', '.pkg.tar.xz.sig', '.pkg.tar.zst', '.pkg.tar.zst.sig')):
      continue
    try:
      os.link(f, os.path.join(dest, f))
    except FileExistsError:
      pass

def git_last_commit() -> str:
  cmd = ['git', 'log', '-1', '--format=%H']
  return run_cmd(cmd).strip()

def start_build(repo: Repo, failed: Set[str], built: Set[str]) -> None:
  # built is used to collect built package names
  global DEPENDS

  building_depmap = {}
  for p in building_packages:
    building_depmap[p] = DEPMAP[p]

  dep_building_map: Dict[str, Set[str]] = {}
  nonexistent: Dict[str, List[Dependency]] = defaultdict(list)
  for name, ds in building_depmap.items():
    for d in ds:
      if not d.resolve():
        if not repo.manages(d):
          logger.warning('%s depends on %s, but it\'s not managed.',
                         name, d)
          nonexistent[name].append(d)
          continue
        # we need build this too
        logger.info('build %s as a dependency of %s because no built package found',
                    d.pkgname, name)
        building_packages[d.pkgname] = ()
        build_reasons[d.pkgname].append(BuildReason.Depended(name))

    dep_building_map[name] = set()
    for x in ds:
      pkgbase = x.pkgdir.name
      dep_building_map[name].add(pkgbase)
      # a dependency may depend other packages, we need their relations
      if pkgbase in DEPMAP:
        dep_building_map[pkgbase] = {
          x.pkgdir.name for x in DEPMAP[pkgbase]}

  for name, deps in nonexistent.items():
    repo.send_error_report(
      repo.mods[name], subject='软件包 %s 的 lilac.{py,yaml} 指定了不存在的依赖',
      msg = f'软件包 {name} 的 lilac.py 或者 lilac.yaml 指定了 repo_depends，然而其直接或者间接的依赖项 {deps!r} 并不在本仓库中。'
    )

  packages = graphlib.TopologicalSorter(dep_building_map).static_order()
  # filter out already built packages
  packages = [x for x in packages if x in building_packages]

  # ensure all packages including dependents are included
  for p in packages:
    building_depmap[p] = DEPMAP[p]

  # used to decide what to install when building
  DEPENDS = building_depmap

  try:
    logger.info('building these packages: %r', packages)
    for pkg in packages:
      if pkg in failed:
        # marked as failed, skip
        continue

      start_time = time.time()
      logger.info('building %s', pkg)
      logfile = logdir / f'{pkg}.log'

      with at_dir(repo.repodir / pkg), \
          logfile.open('wb') as f, \
          redirect_output(f.fileno()):
        r, version = build_package(pkg, repo.mods[pkg])
        elapsed = time.time() - start_time
        logger.info(
          'build (version %s) finished in %ds with result: %r',
          version, elapsed, r,
        )

      logger.info(
        'package %s (version %s) finished in %ds with result: %r',
        pkg, version, elapsed, r,
      )

      newver = nvdata[pkg].newver
      msg = None

      if isinstance(r, BuildResult.successful):
        build_logger_old.info(
          '%s %s [%s] successful after %ds',
          pkg, newver, version, elapsed)
        build_logger.info(
          'successful', pkgbase = pkg,
          nv_version = newver, pkg_version = version, elapsed = elapsed,
        )

      elif isinstance(r, BuildResult.staged):
        build_logger_old.info(
          '%s %s [%s] staged after %ds',
          pkg, newver, version, elapsed)
        build_logger.info(
          'staged', pkgbase = pkg,
          nv_version = newver, pkg_version = version, elapsed = elapsed,
        )

      elif isinstance(r, BuildResult.skipped):
        build_logger_old.warning('%s %s skipped after %ds', pkg, newver, elapsed)
        build_logger.warning(
          'skipped', pkgbase = pkg,
          nv_version = newver, msg = r.reason, elapsed = elapsed,
        )
        msg = r.reason

      elif isinstance(r, BuildResult.failed):
        build_logger_old.error('%s %s [%s] failed after %ds', pkg, newver, version, elapsed)
        build_logger.error(
          'failed', pkgbase = pkg,
          nv_version = newver, elapsed = elapsed, exc_info = r.exc,
        )
        assert r.exc is not None
        handle_failure(r.exc, repo, pkg, logfile, built, failed)
        msg = repr(r.exc)

      if db.USE:
        if r.rusage:
          cputime = r.rusage.ru_utime + r.rusage.ru_stime
          maxrss = r.rusage.ru_maxrss * 1024
        else:
          cputime = maxrss = None
        rs = [r.to_dict() for r in build_reasons[pkg]]
        with db.get_session() as s:
          p = db.PkgLog(
            pkgbase = pkg,
            nv_version = newver,
            pkg_version = version,
            elapsed = elapsed,
            result = r.__class__.__name__,
            cputime = cputime,
            maxrss = maxrss,
            msg = msg,
            build_reasons = json.dumps(rs),
          )
          s.add(p)

      if r:
        built.add(pkg)
      else:
        failed.add(pkg)

  except KeyboardInterrupt:
    logger.info('keyboard interrupted, bye~')

def handle_failure(
  e: Exception, repo: Repo, pkg: str, logfile: Path,
  built: Set[str], failed: Set[str],
) -> None:
  mod = repo.mods[pkg]

  if isinstance(e, pkgbuild.ConflictWithOfficialError):
    reason = ''
    if e.groups:
      reason += f'软件包被加入了官方组：{e.groups}\n'
    if e.packages:
      reason += f'软件包将取代官方包：{e.packages}\n'
    repo.send_error_report(
      mod, subject='%s 与官方软件库冲突', msg = reason,
    )

  elif isinstance(e, MissingDependencies):
    reason = ''
    faileddeps = e.deps & failed
    if faileddeps:
      reason += '唔，这些包没能成功打包呢：%r' % faileddeps

    repo.send_error_report(
      mod, subject='%s 出现依赖问题',
      msg = f'在成功地编译打包 {built} 之后，{pkg} 依旧依赖 {e.deps}。\n\n{reason}',
    )

  elif isinstance(e, pkgbuild.DowngradingError):
    repo.send_error_report(
      mod, subject='%s 新打的包比仓库里的包旧',
      msg=f'包 {e.pkgname} 打的版本为 {e.built_version}，但在仓库里已有较新版本 {e.repo_version}。\n',
    )

  else:
    repo.send_error_report(mod, exc=e, logfile=logfile)

def main_may_raise(D: Dict[str, Any], pkgs_to_build: List[str]) -> None:
  global DEPMAP

  failed_info = D.get('failed', {})

  if get_git_branch() != 'master':
    raise Exception('repo not on master, aborting.')

  if dburl := config['lilac'].get('dburl'):
    import sqlalchemy
    engine = sqlalchemy.create_engine(dburl)
    db.setup(engine)

  git_reset_hard()
  git_pull_override()
  failed = REPO.load_managed_lilac_and_report()

  depman = DependencyManager(REPO.repodir)
  DEPMAP = get_dependency_map(depman, REPO.mods)

  if pkgs_to_build:
    all_mods = REPO.mods
    REPO.mods = {}
    for pkg_to_build in pkgs_to_build:
      for dep in DEPMAP[pkg_to_build]:
        REPO.mods[dep.pkgname] = all_mods[dep.pkgname]
      REPO.mods[pkg_to_build] = all_mods[pkg_to_build]

  proxy = config['nvchecker'].get('proxy')
  _nvdata, unknown, rebuild = packages_need_update(
    REPO, proxy)
  nvdata.update(_nvdata) # update to the global object

  if pkgs_to_build:
    need_update: Set[str] = set()
    need_rebuild_failed: Set[str] = set()
    need_rebuild_pkgrel: Set[str] = set()
  else:
    U = set(REPO.mods)
    last_commit = D.get('last_commit', EMPTY_COMMIT)
    changed = get_changed_packages(last_commit, 'HEAD') & U

    failed_prev = set(failed_info.keys())
    # no update from upstream, but build instructions have changed; rebuild
    # failed ones
    need_rebuild_failed = failed_prev & changed
    # if pkgrel is updated, build a new release
    need_rebuild_pkgrel = {x for x in changed
                          if pkgrel_changed(last_commit, 'HEAD', x)} - unknown

  updated = {x for x, y in nvdata.items()
              if y.oldver != y.newver}
  failed_updated = {k for k, v in failed_info.items()
                    if k in nvdata and nvdata[k].newver != v}
  # build updated; if last build failed but it gets updated once more,
  # build it again
  need_update = updated | failed_updated
  for p, vers in nvdata.items():
    diff_idxs = [i for i, v in enumerate(vers)
                 if v.oldver != v.newver]
    if diff_idxs:
      mod = REPO.mods[p]
      confs = mod.update_on
      sources = [(i, confs[i]['source']) for i in diff_idxs]
      build_reasons[p].append(BuildReason.NvChecker(sources))

  # rebuild first, update later
  all_building: List[str] = []
  all_building.extend(rebuild)

  all_building.extend(pkgs_to_build)
  for p in pkgs_to_build:
    build_reasons[p].append(BuildReason.Cmdline())

  all_building.extend(need_rebuild_pkgrel)
  for p in need_rebuild_pkgrel:
    build_reasons[p].append(BuildReason.UpdatedPkgrel())

  all_building.extend(need_rebuild_failed)
  for p in need_rebuild_failed:
    build_reasons[p].append(BuildReason.UpdatedFailed())

  all_building.extend(need_update)

  logger.info('these updated (pkgrel) packages should be rebuilt: %r',
              need_rebuild_pkgrel or None)
  logger.info('these previously-failed packages should be rebuilt: %r',
              need_rebuild_failed or None)
  logger.info('these packages are updated as detected by nvchecker: %r',
              need_update or None)
  logger.info('these packages need rebuilding'
              ' as detected by nvchecker or manually specified: %r',
              rebuild or None)

  building_packages.update({x: () for x in all_building})
  update_succeeded: Set[str] = set()

  try:
    build_logger.info('build start')
    if db.USE:
      with db.get_session() as s:
        b = db.Batch(event='start')
        s.add(b)
    start_build(REPO, failed, update_succeeded)
    D['last_commit'] = git_last_commit()
  finally:
    # handle what has been processed even on exception
    failed_info.update({k: nvdata[k].newver for k in failed if k in nvdata})

    for x in update_succeeded:
      if x in failed_info:
        del failed_info[x]
    D['failed'] = failed_info

    if config['lilac']['rebuild_failed_pkgs']:
      if update_succeeded:
        nvtake(update_succeeded, REPO.mods)
    else:
      if need_update or rebuild:
        # only nvtake packages we have tried to build (excluding unbuilt
        # packages due to internal errors)
        built = update_succeeded | failed
        update_nv = built & (need_update | rebuild)
        nvtake(update_nv, REPO.mods)

    build_logger.info('build end')
    if db.USE:
      with db.get_session() as s:
        b = db.Batch(event='stop')
        s.add(b)

    git_reset_hard()
    if config['lilac']['git_push']:
      git_push()

def main(pkgs_to_build: List[str]) -> None:
  store = mydir / 'store'
  with PickledData(store, default={}) as D:
    try:
      main_may_raise(D, pkgs_to_build)
    except Exception:
      tb = traceback.format_exc()
      logger.exception('unexpected error')
      subject = '运行时错误'
      msg = '调用栈如下：\n\n' + tb
      REPO.report_error(subject, msg)

def setup() -> None:
  prctl.set_child_subreaper(1)
  global logdir

  logdir = mydir / 'log' / time.strftime('%Y-%m-%dT%H:%M:%S')
  logdir.mkdir(parents=True, exist_ok=True)
  logfile = logdir / 'lilac-main.log'
  fd = os.open(logfile, os.O_WRONLY | os.O_CREAT, 0o644)
  os.dup2(fd, 1)
  os.dup2(fd, 2)
  os.close(fd)

  enable_pretty_logging('DEBUG')
  if 'MAKEFLAGS' not in os.environ:
    cores = os.cpu_count()
    if cores is not None:
      os.environ['MAKEFLAGS'] = '-j{0}'.format(cores)

  lock_file(mydir / '.lock')

  setup_build_logger()
  os.chdir(REPO.repodir)

  pkgbuild.init_data(PACMAN_DB_DIR)

if __name__ == '__main__':
  try:
    setup()

    main(sys.argv[1:])
  except Exception:
    logger.exception('unexpected error')
